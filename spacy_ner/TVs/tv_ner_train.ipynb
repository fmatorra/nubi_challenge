{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0102b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c1ea677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list\n",
    "#!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882fbbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Marca</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>class(TV, SMART, OTRO)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Smart Tv Noblex Di43x5100x Led Full Hd 43  220v</td>\n",
       "      <td>Noblex</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Smart Tv Tcl L42s6500 Led Full Hd 42  220v</td>\n",
       "      <td>Tcl</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tv Samsung Smart Tv Hd 32 Para Repuestos</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tv Led Samsung 46 Smart Pantalla Rota</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tv 29 Sanyo Vizon</td>\n",
       "      <td>Sanyo</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Title    Marca  start   end  \\\n",
       "0  Smart Tv Noblex Di43x5100x Led Full Hd 43  220v   Noblex    9.0  15.0   \n",
       "1       Smart Tv Tcl L42s6500 Led Full Hd 42  220v      Tcl    9.0  12.0   \n",
       "2         Tv Samsung Smart Tv Hd 32 Para Repuestos  Samsung    3.0  10.0   \n",
       "3            Tv Led Samsung 46 Smart Pantalla Rota  Samsung    7.0  14.0   \n",
       "4                                Tv 29 Sanyo Vizon    Sanyo    6.0  11.0   \n",
       "\n",
       "   class(TV, SMART, OTRO)  \n",
       "0                       1  \n",
       "1                       1  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./training_data/tv_ner_textcat_100.csv')\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a1cf79",
   "metadata": {},
   "source": [
    "## Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77b7154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DATA = []\n",
    "\n",
    "for index, row in data.iterrows(): \n",
    "    text = row['Title']\n",
    "    start = row['start']\n",
    "    end = row['end']\n",
    "    entities = []\n",
    "    #print(start)\n",
    "    if math.isnan(start):\n",
    "        #print('no ent')\n",
    "        pass\n",
    "    else:        \n",
    "        entities.append((int(start), int(end), \"MARCA\"))            \n",
    "        \n",
    "    \n",
    "    #print(dup_start)\n",
    "    training_example = (text, {\"entities\": entities})\n",
    "    TRAINING_DATA.append(training_example)\n",
    "\n",
    "print(len(TRAINING_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb01c460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 775.07it/s]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import srsly\n",
    "from spacy.gold import docs_to_json, biluo_tags_from_offsets, spans_from_biluo_tags\n",
    "from tqdm import tqdm\n",
    "#spacy.prefer_gpu()\n",
    "#TRAIN_DATA = [\n",
    "#    (\"Who is Shaka Khan?\", {\"entities\": [(7, 17, \"PERSON\")]}),\n",
    "#    (\"I like London and Berlin.\", {\"entities\": [(7, 13, \"LOC\"), (18, 24, \"LOC\")]}),\n",
    "#]\n",
    "\n",
    "#nlp = spacy.blank(\"en\")\n",
    "nlp = spacy.load('es_core_news_sm', disable = ['tagger', 'ner'])\n",
    "#nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "nlp.max_length = 1500000\n",
    "docs = []\n",
    "for text, annot in tqdm(TRAINING_DATA):\n",
    "    if len(text) < 1000000:\n",
    "        doc = nlp(text)\n",
    "        tags = biluo_tags_from_offsets(doc, annot['entities'])\n",
    "        entities = spans_from_biluo_tags(doc, tags)\n",
    "        doc.ents = entities\n",
    "        docs.append(doc)\n",
    "\n",
    "srsly.write_json(\"./training_data/tv_ner_100.json\", [docs_to_json(docs)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54e02d2",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "812f22c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "=========================== Data format validation ===========================\u001b[0m\n",
      "\u001b[2K\u001b[38;5;2m✔ Corpus is loadable\u001b[0m\n",
      "\u001b[1m\n",
      "=============================== Training stats ===============================\u001b[0m\n",
      "Training pipeline: tagger, parser, ner\n",
      "Starting with blank model 'es'\n",
      "102 training docs\n",
      "102 evaluation docs\n",
      "\u001b[38;5;3m⚠ 102 training examples also in evaluation data\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples to train from a blank model (102)\u001b[0m\n",
      "It's recommended to use at least 2000 examples (minimum 100)\n",
      "\u001b[1m\n",
      "============================== Vocab & Vectors ==============================\u001b[0m\n",
      "\u001b[38;5;4mℹ 768 total words in the data (229 unique)\u001b[0m\n",
      "10 most common words: 'Tv' (77), 'Smart' (44), ' ' (30), 'Led' (29), 'Pulgadas'\n",
      "(23), 'Televisor' (22), 'Hd' (21), 'Samsung' (21), '32' (19), '4k' (16)\n",
      "\u001b[38;5;4mℹ No word vectors present in the model\u001b[0m\n",
      "\u001b[1m\n",
      "========================== Named Entity Recognition ==========================\u001b[0m\n",
      "\u001b[38;5;4mℹ 1 new label, 0 existing labels\u001b[0m\n",
      "0 missing values (tokens with '-' label)\n",
      "New: 'MARCA' (95)\n",
      "\u001b[38;5;2m✔ Good amount of examples for all labels\u001b[0m\n",
      "\u001b[38;5;2m✔ Examples without occurrences available for all labels\u001b[0m\n",
      "\u001b[38;5;2m✔ No entities consisting of or starting/ending with whitespace\u001b[0m\n",
      "\u001b[38;5;2m✔ No entities consisting of or starting/ending with punctuation\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Part-of-speech Tagging ===========================\u001b[0m\n",
      "\u001b[38;5;4mℹ 1 label in data (303 labels in tag map)\u001b[0m\n",
      "'-' (768)\n",
      "\u001b[38;5;1m✘ Label '-' not found in tag map for language 'es'\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Dependency Parsing =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Found 107 sentences with an average length of 7.2 words.\u001b[0m\n",
      "\u001b[38;5;3m⚠ The training data contains 1.05 sentences per document. When there\n",
      "are very few documents containing more than one sentence, the parser will not\n",
      "learn how to segment longer texts into sentences.\u001b[0m\n",
      "\u001b[38;5;4mℹ 16 labels in train data\u001b[0m\n",
      "\u001b[38;5;4mℹ 16 labels in projectivized train data\u001b[0m\n",
      "'flat' (370), 'nummod' (109), 'ROOT' (107), 'punct' (35), 'appos' (34), '' (32),\n",
      "'dep' (25), 'case' (24), 'nmod' (9), 'obj' (7), 'conj' (5), 'cc' (4), 'nsubj'\n",
      "(3), 'det' (2), 'mark' (1), 'amod' (1)\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'det' (2)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'nsubj' (3)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'nmod' (9)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'obj' (7)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'cc' (4)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'conj' (5)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'mark' (1)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'amod' (1)\u001b[0m\n",
      "To train a parser, your data should include at least 20 instances of each label.\n",
      "\u001b[1m\n",
      "================================== Summary ==================================\u001b[0m\n",
      "\u001b[38;5;2m✔ 5 checks passed\u001b[0m\n",
      "\u001b[38;5;3m⚠ 11 warnings\u001b[0m\n",
      "\u001b[38;5;1m✘ 1 error\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy debug-data es '/home/fede/kaggle/desafio_ia_nlp_nubimetrics/spacy_ner/TVs/training_data/tv_ner_100.json' '/home/fede/kaggle/desafio_ia_nlp_nubimetrics/spacy_ner/TVs/training_data/tv_ner_100.json' --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09ad5ca",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7567cc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created output directory: models/NUBI-TV-NER-100\u001b[0m\n",
      "Training pipeline: ['ner']\n",
      "Starting with base model 'es_core_news_sm'\n",
      "Replacing component from base model 'ner'\n",
      "Counting training words (limit=0)\n",
      "/home/fede/anaconda3/envs/spacy_env/lib/python3.8/site-packages/spacy/language.py:635: UserWarning: [W033] Training a new parser or NER using a model with an empty lexeme normalization table. This may degrade the performance to some degree. If this is intentional or this language doesn't have a normalization table, please ignore this warning.\n",
      "  proc.begin_training(\n",
      "\n",
      "Itn  NER Loss   NER P   NER R   NER F   Token %  CPU WPS\n",
      "---  ---------  ------  ------  ------  -------  -------\n",
      "  1    506.637   0.000   0.000   0.000  100.000    31035                        \n",
      "  2    170.482   0.000   0.000   0.000  100.000    35037                        \n",
      "  3     89.347  97.297  75.789  85.207  100.000    32915                        \n",
      "  4     30.437  93.814  95.789  94.792  100.000    29814                        \n",
      "  5      8.552  97.872  96.842  97.354  100.000    34124                        \n",
      "  6      4.976  97.895  97.895  97.895  100.000    33069                        \n",
      "  7      1.906  100.000  100.000  100.000  100.000    33678                     \n",
      "  8      6.269  100.000  100.000  100.000  100.000    32588                     \n",
      "  9      6.097  97.895  97.895  97.895  100.000    33461                        \n",
      " 10      3.995  98.958  100.000  99.476  100.000    32954                       \n",
      " 11      0.777  100.000  100.000  100.000  100.000    33863                     \n",
      " 12      1.638  100.000  100.000  100.000  100.000    33155                     \n",
      " 13      0.001  100.000  100.000  100.000  100.000    34042                     \n",
      " 14      0.028  100.000  100.000  100.000  100.000    34593                     \n",
      " 15      0.002  100.000  100.000  100.000  100.000    34110                     \n",
      " 16      0.000  100.000  100.000  100.000  100.000    33727                     \n",
      " 17      0.000  100.000  100.000  100.000  100.000    34024                     \n",
      " 18      0.365  100.000  100.000  100.000  100.000    33398                     \n",
      " 19      0.000  100.000  100.000  100.000  100.000    32717                     \n",
      " 20      0.000  100.000  100.000  100.000  100.000    33941                     \n",
      " 21      0.000  100.000  100.000  100.000  100.000    33427                     \n",
      " 22      0.000  100.000  100.000  100.000  100.000    34738                     \n",
      " 23      0.001  100.000  100.000  100.000  100.000    32337                     \n",
      " 24      0.000  100.000  100.000  100.000  100.000    34558                     \n",
      " 25      0.000  100.000  100.000  100.000  100.000    33670                     \n",
      " 26      0.516  100.000  100.000  100.000  100.000    33710                     \n",
      " 27      0.000  100.000  100.000  100.000  100.000    34783                     \n",
      " 28      0.001  100.000  100.000  100.000  100.000    34224                     \n",
      " 29      0.000  100.000  100.000  100.000  100.000    34697                     \n",
      " 30      0.000  100.000  100.000  100.000  100.000    33424                     \n",
      "\u001b[38;5;2m✔ Saved model to output directory\u001b[0m\n",
      "models/NUBI-TV-NER-100/model-final\n",
      "\u001b[2K\u001b[38;5;2m✔ Created best model\u001b[0m\n",
      "models/NUBI-TV-NER-100/model-best\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train es ./models/NUBI-TV-NER-100 '/home/fede/kaggle/desafio_ia_nlp_nubimetrics/spacy_ner/TVs/training_data/tv_ner_100.json' '/home/fede/kaggle/desafio_ia_nlp_nubimetrics/spacy_ner/TVs/training_data/tv_ner_100.json' --base-model 'es_core_news_sm' -p ner -R\n",
    "#SAco el modelo de base\n",
    "#!python -m spacy train en NER-SECOND-EMPTY-VEC-15000 '/home/fede/kaggle_competition_2/spacy_2.3.5/data_for_training/train_sent_12500_format.json' '/home/fede/kaggle_competition_2/spacy_2.3.5/data_for_training/dev_sent_3100_format.json' --vectors '/home/fede/kaggle_competition_2/spacy_2.3.5/Diego/w2v-w11-f7-50-spacy'  -p ner -R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd13490d",
   "metadata": {},
   "source": [
    "## Celular Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4349c6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('./models/NUBI-TV-NER-100/model-best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9197bdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Encrypted_Seller</th>\n",
       "      <th>Encrypted_Id</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b10532ee783f9545d7bddd8f9da20d2a8d1642a486caf5...</td>\n",
       "      <td>63c875becd6c78649539497bdd134c2c762f610b3616ae...</td>\n",
       "      <td>Smart Tv Noblex Di43x5100x Led Full Hd 43  220v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>aa4dd7ba40c80cf15a859c19f2500e328797e2251322d4...</td>\n",
       "      <td>490e4b75cfa66087c95b20fb6546e4dfdc952f7537a8e3...</td>\n",
       "      <td>Smart Tv Tcl L42s6500 Led Full Hd 42  220v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>e48526711c7cd386af46750540bf107acac9b5988b515a...</td>\n",
       "      <td>eab7301d49cd3bbe3bcd3c196da0d61713de45b44523c1...</td>\n",
       "      <td>Tv Samsung Smart Tv Hd 32 Para Repuestos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9e527f7876123f50719291aed05c8351bab1ae9abacadb...</td>\n",
       "      <td>daf900de69964f2cf241ed5395ac74edd1f2deb6577356...</td>\n",
       "      <td>Tv Led Samsung 46 Smart Pantalla Rota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cf3021aa458178431fa2f22daa52ee17f005d6728d9b35...</td>\n",
       "      <td>b244c68806fab7d7d523a3927a4eb6381610c40313e8bb...</td>\n",
       "      <td>Tv 29 Sanyo Vizon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                   Encrypted_Seller  \\\n",
       "0           0  b10532ee783f9545d7bddd8f9da20d2a8d1642a486caf5...   \n",
       "1           1  aa4dd7ba40c80cf15a859c19f2500e328797e2251322d4...   \n",
       "2           2  e48526711c7cd386af46750540bf107acac9b5988b515a...   \n",
       "3           3  9e527f7876123f50719291aed05c8351bab1ae9abacadb...   \n",
       "4           4  cf3021aa458178431fa2f22daa52ee17f005d6728d9b35...   \n",
       "\n",
       "                                        Encrypted_Id  \\\n",
       "0  63c875becd6c78649539497bdd134c2c762f610b3616ae...   \n",
       "1  490e4b75cfa66087c95b20fb6546e4dfdc952f7537a8e3...   \n",
       "2  eab7301d49cd3bbe3bcd3c196da0d61713de45b44523c1...   \n",
       "3  daf900de69964f2cf241ed5395ac74edd1f2deb6577356...   \n",
       "4  b244c68806fab7d7d523a3927a4eb6381610c40313e8bb...   \n",
       "\n",
       "                                             Title  \n",
       "0  Smart Tv Noblex Di43x5100x Led Full Hd 43  220v  \n",
       "1       Smart Tv Tcl L42s6500 Led Full Hd 42  220v  \n",
       "2         Tv Samsung Smart Tv Hd 32 Para Repuestos  \n",
       "3            Tv Led Samsung 46 Smart Pantalla Rota  \n",
       "4                                Tv 29 Sanyo Vizon  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate = pd.read_csv('../../TVs.csv') #/home/fede/kaggle/desafio_ia_nlp_nubimetrics/TVs.csv\n",
    "evaluate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "427b2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "marca = []\n",
    "start = []\n",
    "end = []\n",
    "\n",
    "for doc in nlp.pipe(evaluate['Title'][:1000]):    \n",
    "    #displacy.render(doc, style=\"ent\")\n",
    "    ent_count = 0\n",
    "    for ent in doc.ents:\n",
    "        #print(doc.text, ent.text, ent.start_char, ent.end_char)\n",
    "        if ent_count == 1:\n",
    "            pass\n",
    "        else:        \n",
    "            marca.append(ent.text)\n",
    "            start.append(ent.start_char)\n",
    "            end.append(ent.end_char)\n",
    "            ent_count = 1\n",
    "    if ent_count == 0:    \n",
    "        marca.append('##REV')\n",
    "        start.append('##REV')\n",
    "        end.append('##REV')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74e6f980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(marca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e0f4bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1000 = evaluate.loc[:999, :].copy()\n",
    "df_1000['marca'] = marca\n",
    "df_1000['start'] = start\n",
    "df_1000['end'] = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9897ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1000.to_csv(\"./training_data/tv_ner_textcat_1000_corregir.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d322c7",
   "metadata": {},
   "source": [
    "## Celular data 1000 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75367b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Encrypted_Seller</th>\n",
       "      <th>Encrypted_Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>marca</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b10532ee783f9545d7bddd8f9da20d2a8d1642a486caf5...</td>\n",
       "      <td>63c875becd6c78649539497bdd134c2c762f610b3616ae...</td>\n",
       "      <td>Smart Tv Noblex Di43x5100x Led Full Hd 43  220v</td>\n",
       "      <td>Noblex</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>aa4dd7ba40c80cf15a859c19f2500e328797e2251322d4...</td>\n",
       "      <td>490e4b75cfa66087c95b20fb6546e4dfdc952f7537a8e3...</td>\n",
       "      <td>Smart Tv Tcl L42s6500 Led Full Hd 42  220v</td>\n",
       "      <td>Tcl</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>e48526711c7cd386af46750540bf107acac9b5988b515a...</td>\n",
       "      <td>eab7301d49cd3bbe3bcd3c196da0d61713de45b44523c1...</td>\n",
       "      <td>Tv Samsung Smart Tv Hd 32 Para Repuestos</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9e527f7876123f50719291aed05c8351bab1ae9abacadb...</td>\n",
       "      <td>daf900de69964f2cf241ed5395ac74edd1f2deb6577356...</td>\n",
       "      <td>Tv Led Samsung 46 Smart Pantalla Rota</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cf3021aa458178431fa2f22daa52ee17f005d6728d9b35...</td>\n",
       "      <td>b244c68806fab7d7d523a3927a4eb6381610c40313e8bb...</td>\n",
       "      <td>Tv 29 Sanyo Vizon</td>\n",
       "      <td>Sanyo</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                   Encrypted_Seller  \\\n",
       "0           0  b10532ee783f9545d7bddd8f9da20d2a8d1642a486caf5...   \n",
       "1           1  aa4dd7ba40c80cf15a859c19f2500e328797e2251322d4...   \n",
       "2           2  e48526711c7cd386af46750540bf107acac9b5988b515a...   \n",
       "3           3  9e527f7876123f50719291aed05c8351bab1ae9abacadb...   \n",
       "4           4  cf3021aa458178431fa2f22daa52ee17f005d6728d9b35...   \n",
       "\n",
       "                                        Encrypted_Id  \\\n",
       "0  63c875becd6c78649539497bdd134c2c762f610b3616ae...   \n",
       "1  490e4b75cfa66087c95b20fb6546e4dfdc952f7537a8e3...   \n",
       "2  eab7301d49cd3bbe3bcd3c196da0d61713de45b44523c1...   \n",
       "3  daf900de69964f2cf241ed5395ac74edd1f2deb6577356...   \n",
       "4  b244c68806fab7d7d523a3927a4eb6381610c40313e8bb...   \n",
       "\n",
       "                                             Title    marca  start   end  \n",
       "0  Smart Tv Noblex Di43x5100x Led Full Hd 43  220v   Noblex    9.0  15.0  \n",
       "1       Smart Tv Tcl L42s6500 Led Full Hd 42  220v      Tcl    9.0  12.0  \n",
       "2         Tv Samsung Smart Tv Hd 32 Para Repuestos  Samsung    3.0  10.0  \n",
       "3            Tv Led Samsung 46 Smart Pantalla Rota  Samsung    7.0  14.0  \n",
       "4                                Tv 29 Sanyo Vizon    Sanyo    6.0  11.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./training_data/tv_ner_textcat_1000.csv')\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e23213b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DATA = []\n",
    "\n",
    "for index, row in data.iterrows(): \n",
    "    text = row['Title']\n",
    "    start = row['start']\n",
    "    end = row['end']\n",
    "    entities = []\n",
    "    #print(start)\n",
    "    if math.isnan(start):\n",
    "        pass\n",
    "        #print('no ent')\n",
    "    else:        \n",
    "        entities.append((int(start), int(end), \"MARCA\"))            \n",
    "        \n",
    "    \n",
    "    #print(dup_start)\n",
    "    training_example = (text, {\"entities\": entities})\n",
    "    TRAINING_DATA.append(training_example)\n",
    "\n",
    "print(len(TRAINING_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "562c3693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "#TRAINING_DATA\n",
    "random.seed(0)\n",
    "l = list(TRAINING_DATA)\n",
    "random.shuffle(l)\n",
    "#print(l)\n",
    "length = len(TRAINING_DATA)\n",
    "index_80 = length*0.80\n",
    "train = l[:int(index_80)]\n",
    "dev = l[int(index_80):]\n",
    "print(len(train))\n",
    "print(len(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d798f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import srsly\n",
    "from spacy.gold import docs_to_json, biluo_tags_from_offsets, spans_from_biluo_tags\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "nlp = spacy.load('es_core_news_sm', disable = ['tagger', 'ner'])\n",
    "#nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "nlp.max_length = 1500000\n",
    "\n",
    "def spacy_format(data, test_train):    \n",
    "    docs = []\n",
    "    for text, annot in tqdm(data):\n",
    "        if len(text) < 1000000:\n",
    "            doc = nlp(text)\n",
    "            tags = biluo_tags_from_offsets(doc, annot['entities'])\n",
    "            entities = spans_from_biluo_tags(doc, tags)\n",
    "            doc.ents = entities\n",
    "            docs.append(doc)\n",
    "\n",
    "    srsly.write_json(f'./training_data/tv_ner_1000_{test_train}.json', [docs_to_json(docs)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cde8dbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/800 [00:00<?, ?it/s]/tmp/ipykernel_11132/3594294779.py:16: UserWarning: [W030] Some entities could not be aligned in the text \"Tv 14 Hitachi/ Broksonic/ Admiral/ Top House/ Vari...\" with entities \"[(15, 24, 'MARCA')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  tags = biluo_tags_from_offsets(doc, annot['entities'])\n",
      "100%|██████████| 800/800 [00:01<00:00, 776.74it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 780.49it/s]\n"
     ]
    }
   ],
   "source": [
    "spacy_format(train, 'train')\n",
    "spacy_format(dev, 'dev')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39b1e76",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b51aef89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "=========================== Data format validation ===========================\u001b[0m\n",
      "\u001b[2K\u001b[38;5;2m✔ Corpus is loadable\u001b[0m\n",
      "\u001b[1m\n",
      "=============================== Training stats ===============================\u001b[0m\n",
      "Training pipeline: tagger, parser, ner\n",
      "Starting with blank model 'es'\n",
      "800 training docs\n",
      "200 evaluation docs\n",
      "\u001b[38;5;3m⚠ 9 training examples also in evaluation data\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples to train from a blank model (800)\u001b[0m\n",
      "It's recommended to use at least 2000 examples (minimum 100)\n",
      "\u001b[1m\n",
      "============================== Vocab & Vectors ==============================\u001b[0m\n",
      "\u001b[38;5;4mℹ 6066 total words in the data (845 unique)\u001b[0m\n",
      "10 most common words: 'Tv' (587), 'Smart' (319), 'Led' (260), ' ' (254), '32'\n",
      "(192), 'Pulgadas' (187), 'Televisor' (179), 'Samsung' (154), 'Hd' (147), '4k'\n",
      "(121)\n",
      "\u001b[38;5;4mℹ No word vectors present in the model\u001b[0m\n",
      "\u001b[1m\n",
      "========================== Named Entity Recognition ==========================\u001b[0m\n",
      "\u001b[38;5;4mℹ 1 new label, 0 existing labels\u001b[0m\n",
      "0 missing values (tokens with '-' label)\n",
      "New: 'MARCA' (737)\n",
      "\u001b[38;5;2m✔ Good amount of examples for all labels\u001b[0m\n",
      "\u001b[38;5;2m✔ Examples without occurrences available for all labels\u001b[0m\n",
      "\u001b[38;5;2m✔ No entities consisting of or starting/ending with whitespace\u001b[0m\n",
      "\u001b[38;5;2m✔ No entities consisting of or starting/ending with punctuation\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Part-of-speech Tagging ===========================\u001b[0m\n",
      "\u001b[38;5;4mℹ 1 label in data (303 labels in tag map)\u001b[0m\n",
      "'-' (6066)\n",
      "\u001b[38;5;1m✘ Label '-' not found in tag map for language 'es'\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Dependency Parsing =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Found 860 sentences with an average length of 7.1 words.\u001b[0m\n",
      "\u001b[38;5;3m⚠ The training data contains 1.10 sentences per document. When there\n",
      "are very few documents containing more than one sentence, the parser will not\n",
      "learn how to segment longer texts into sentences.\u001b[0m\n",
      "\u001b[38;5;4mℹ 27 labels in train data\u001b[0m\n",
      "\u001b[38;5;4mℹ 27 labels in projectivized train data\u001b[0m\n",
      "'flat' (2882), 'ROOT' (860), 'nummod' (824), '' (280), 'punct' (270), 'case'\n",
      "(203), 'appos' (165), 'dep' (113), 'nsubj' (93), 'nmod' (90), 'obj' (87), 'conj'\n",
      "(58), 'cc' (54), 'advmod' (20), 'amod' (15), 'mark' (14), 'obl' (12), 'det'\n",
      "(10), 'compound' (6), 'advcl' (2), 'acl' (2), 'ccomp' (1), 'parataxis' (1),\n",
      "'cop' (1), 'aux' (1), 'xcomp' (1), 'csubj' (1)\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'compound' (6)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'advmod' (20)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'advcl' (2)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'mark' (14)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'acl' (2)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'amod' (15)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'obl' (12)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'det' (10)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'ccomp' (1)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'parataxis' (1)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'cop' (1)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'aux' (1)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'xcomp' (1)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'csubj' (1)\u001b[0m\n",
      "\u001b[38;5;3m⚠ The following labels were found only in the train data: aux, csubj,\n",
      "compound, parataxis, xcomp, advcl, ccomp\u001b[0m\n",
      "To train a parser, your data should include at least 20 instances of each label.\n",
      "\u001b[1m\n",
      "================================== Summary ==================================\u001b[0m\n",
      "\u001b[38;5;2m✔ 5 checks passed\u001b[0m\n",
      "\u001b[38;5;3m⚠ 18 warnings\u001b[0m\n",
      "\u001b[38;5;1m✘ 1 error\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy debug-data es '/home/fede/kaggle/desafio_ia_nlp_nubimetrics/spacy_ner/TVs/training_data/tv_ner_1000_train.json' '/home/fede/kaggle/desafio_ia_nlp_nubimetrics/spacy_ner/TVs/training_data/tv_ner_1000_dev.json' --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2824145",
   "metadata": {},
   "source": [
    "# Train 1000 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "442d9b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created output directory: NUBI-TV-NER-1000\u001b[0m\n",
      "Training pipeline: ['ner']\n",
      "Starting with base model 'es_core_news_sm'\n",
      "Replacing component from base model 'ner'\n",
      "Counting training words (limit=0)\n",
      "/home/fede/anaconda3/envs/spacy_env/lib/python3.8/site-packages/spacy/language.py:635: UserWarning: [W033] Training a new parser or NER using a model with an empty lexeme normalization table. This may degrade the performance to some degree. If this is intentional or this language doesn't have a normalization table, please ignore this warning.\n",
      "  proc.begin_training(\n",
      "\n",
      "Itn  NER Loss   NER P   NER R   NER F   Token %  CPU WPS\n",
      "---  ---------  ------  ------  ------  -------  -------\n",
      "  1    977.767  92.896  92.896  92.896  100.000    31970                        \n",
      "  2     85.034  95.652  96.175  95.913  100.000    32535                        \n",
      "  3     38.335  97.238  96.175  96.703  100.000    33369                        \n",
      "  4     28.701  98.333  96.721  97.521  100.000    33015                        \n",
      "  5     41.763  97.790  96.721  97.253  100.000    33940                        \n",
      "  6      7.140  98.876  96.175  97.507  100.000    33384                        \n",
      "  7     12.513  97.778  96.175  96.970  100.000    33607                        \n",
      "  8     19.727  97.778  96.175  96.970  100.000    32339                        \n",
      "  9      8.486  98.883  96.721  97.790  100.000    30945                        \n",
      " 10      3.781  99.435  96.175  97.778  100.000    34065                        \n",
      " 11     14.391  98.870  95.628  97.222  100.000    34390                        \n",
      " 12      2.028  98.876  96.175  97.507  100.000    32192                        \n",
      " 13      3.420  98.876  96.175  97.507  100.000    33861                        \n",
      " 14      0.254  98.876  96.175  97.507  100.000    34284                        \n",
      " 15      4.680  98.876  96.175  97.507  100.000    33248                        \n",
      " 16      0.555  98.324  96.175  97.238  100.000    33509                        \n",
      " 17      4.977  98.324  96.175  97.238  100.000    33735                        \n",
      " 18      0.006  98.324  96.175  97.238  100.000    34586                        \n",
      " 19      0.118  98.315  95.628  96.953  100.000    33464                        \n",
      " 20      1.920  98.315  95.628  96.953  100.000    33538                        \n",
      " 21      1.599  98.315  95.628  96.953  100.000    33988                        \n",
      " 22      2.029  98.315  95.628  96.953  100.000    34365                        \n",
      " 23      0.069  99.435  96.175  97.778  100.000    34131                        \n",
      " 24      2.819  99.435  96.175  97.778  100.000    34285                        \n",
      " 25      1.788  99.435  96.175  97.778  100.000    34272                        \n",
      " 26      0.000  99.435  96.175  97.778  100.000    33560                        \n",
      " 27      0.000  99.435  96.175  97.778  100.000    33376                        \n",
      " 28      2.047  99.435  96.175  97.778  100.000    33866                        \n",
      " 29      1.994  99.435  96.175  97.778  100.000    34003                        \n",
      " 30      3.948  99.435  96.175  97.778  100.000    33368                        \n",
      "\u001b[38;5;2m✔ Saved model to output directory\u001b[0m\n",
      "NUBI-TV-NER-1000/model-final\n",
      "\u001b[2K\u001b[38;5;2m✔ Created best model\u001b[0m\n",
      "NUBI-TV-NER-1000/model-best\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train es ./models/NUBI-TV-NER-1000 '/home/fede/kaggle/desafio_ia_nlp_nubimetrics/spacy_ner/TVs/training_data/tv_ner_1000_train.json' '/home/fede/kaggle/desafio_ia_nlp_nubimetrics/spacy_ner/TVs/training_data/tv_ner_1000_dev.json' --base-model 'es_core_news_sm' -p ner -R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672c402d",
   "metadata": {},
   "source": [
    "# Inference 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2133a004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('./models/NUBI-TV-NER-1000/model-best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "074784c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Encrypted_Seller</th>\n",
       "      <th>Encrypted_Id</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b10532ee783f9545d7bddd8f9da20d2a8d1642a486caf5...</td>\n",
       "      <td>63c875becd6c78649539497bdd134c2c762f610b3616ae...</td>\n",
       "      <td>Smart Tv Noblex Di43x5100x Led Full Hd 43  220v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>aa4dd7ba40c80cf15a859c19f2500e328797e2251322d4...</td>\n",
       "      <td>490e4b75cfa66087c95b20fb6546e4dfdc952f7537a8e3...</td>\n",
       "      <td>Smart Tv Tcl L42s6500 Led Full Hd 42  220v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>e48526711c7cd386af46750540bf107acac9b5988b515a...</td>\n",
       "      <td>eab7301d49cd3bbe3bcd3c196da0d61713de45b44523c1...</td>\n",
       "      <td>Tv Samsung Smart Tv Hd 32 Para Repuestos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9e527f7876123f50719291aed05c8351bab1ae9abacadb...</td>\n",
       "      <td>daf900de69964f2cf241ed5395ac74edd1f2deb6577356...</td>\n",
       "      <td>Tv Led Samsung 46 Smart Pantalla Rota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cf3021aa458178431fa2f22daa52ee17f005d6728d9b35...</td>\n",
       "      <td>b244c68806fab7d7d523a3927a4eb6381610c40313e8bb...</td>\n",
       "      <td>Tv 29 Sanyo Vizon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                   Encrypted_Seller  \\\n",
       "0           0  b10532ee783f9545d7bddd8f9da20d2a8d1642a486caf5...   \n",
       "1           1  aa4dd7ba40c80cf15a859c19f2500e328797e2251322d4...   \n",
       "2           2  e48526711c7cd386af46750540bf107acac9b5988b515a...   \n",
       "3           3  9e527f7876123f50719291aed05c8351bab1ae9abacadb...   \n",
       "4           4  cf3021aa458178431fa2f22daa52ee17f005d6728d9b35...   \n",
       "\n",
       "                                        Encrypted_Id  \\\n",
       "0  63c875becd6c78649539497bdd134c2c762f610b3616ae...   \n",
       "1  490e4b75cfa66087c95b20fb6546e4dfdc952f7537a8e3...   \n",
       "2  eab7301d49cd3bbe3bcd3c196da0d61713de45b44523c1...   \n",
       "3  daf900de69964f2cf241ed5395ac74edd1f2deb6577356...   \n",
       "4  b244c68806fab7d7d523a3927a4eb6381610c40313e8bb...   \n",
       "\n",
       "                                             Title  \n",
       "0  Smart Tv Noblex Di43x5100x Led Full Hd 43  220v  \n",
       "1       Smart Tv Tcl L42s6500 Led Full Hd 42  220v  \n",
       "2         Tv Samsung Smart Tv Hd 32 Para Repuestos  \n",
       "3            Tv Led Samsung 46 Smart Pantalla Rota  \n",
       "4                                Tv 29 Sanyo Vizon  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate = pd.read_csv('../../TVs.csv')\n",
    "evaluate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d1a49a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "marca = []\n",
    "start = []\n",
    "end = []\n",
    "\n",
    "for doc in nlp.pipe(evaluate['Title']):    \n",
    "    #displacy.render(doc, style=\"ent\")\n",
    "    ent_count = 0\n",
    "    for ent in doc.ents:\n",
    "        #print(doc.text, ent.text, ent.start_char, ent.end_char)\n",
    "        if ent_count == 1:\n",
    "            pass\n",
    "        else:        \n",
    "            marca.append(ent.text)\n",
    "            start.append(ent.start_char)\n",
    "            end.append(ent.end_char)\n",
    "            ent_count = 1\n",
    "    if ent_count == 0:    \n",
    "        marca.append('##REV')\n",
    "        start.append('##REV')\n",
    "        end.append('##REV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "467f19c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = evaluate.loc[:, :].copy()\n",
    "df_all['marca'] = marca\n",
    "df_all['start'] = start\n",
    "df_all['end'] = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61126e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(\"./bd_tv_ner_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96598cbb",
   "metadata": {},
   "source": [
    "## Celular data 1077 examples (Corregidos luego de la inferencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd8fbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Encrypted_Seller</th>\n",
       "      <th>Encrypted_Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>marca</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b10532ee783f9545d7bddd8f9da20d2a8d1642a486caf5...</td>\n",
       "      <td>63c875becd6c78649539497bdd134c2c762f610b3616ae...</td>\n",
       "      <td>Smart Tv Noblex Di43x5100x Led Full Hd 43  220v</td>\n",
       "      <td>Noblex</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>aa4dd7ba40c80cf15a859c19f2500e328797e2251322d4...</td>\n",
       "      <td>490e4b75cfa66087c95b20fb6546e4dfdc952f7537a8e3...</td>\n",
       "      <td>Smart Tv Tcl L42s6500 Led Full Hd 42  220v</td>\n",
       "      <td>Tcl</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>e48526711c7cd386af46750540bf107acac9b5988b515a...</td>\n",
       "      <td>eab7301d49cd3bbe3bcd3c196da0d61713de45b44523c1...</td>\n",
       "      <td>Tv Samsung Smart Tv Hd 32 Para Repuestos</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9e527f7876123f50719291aed05c8351bab1ae9abacadb...</td>\n",
       "      <td>daf900de69964f2cf241ed5395ac74edd1f2deb6577356...</td>\n",
       "      <td>Tv Led Samsung 46 Smart Pantalla Rota</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cf3021aa458178431fa2f22daa52ee17f005d6728d9b35...</td>\n",
       "      <td>b244c68806fab7d7d523a3927a4eb6381610c40313e8bb...</td>\n",
       "      <td>Tv 29 Sanyo Vizon</td>\n",
       "      <td>Sanyo</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                   Encrypted_Seller  \\\n",
       "0           0  b10532ee783f9545d7bddd8f9da20d2a8d1642a486caf5...   \n",
       "1           1  aa4dd7ba40c80cf15a859c19f2500e328797e2251322d4...   \n",
       "2           2  e48526711c7cd386af46750540bf107acac9b5988b515a...   \n",
       "3           3  9e527f7876123f50719291aed05c8351bab1ae9abacadb...   \n",
       "4           4  cf3021aa458178431fa2f22daa52ee17f005d6728d9b35...   \n",
       "\n",
       "                                        Encrypted_Id  \\\n",
       "0  63c875becd6c78649539497bdd134c2c762f610b3616ae...   \n",
       "1  490e4b75cfa66087c95b20fb6546e4dfdc952f7537a8e3...   \n",
       "2  eab7301d49cd3bbe3bcd3c196da0d61713de45b44523c1...   \n",
       "3  daf900de69964f2cf241ed5395ac74edd1f2deb6577356...   \n",
       "4  b244c68806fab7d7d523a3927a4eb6381610c40313e8bb...   \n",
       "\n",
       "                                             Title    marca  start   end  \n",
       "0  Smart Tv Noblex Di43x5100x Led Full Hd 43  220v   Noblex    9.0  15.0  \n",
       "1       Smart Tv Tcl L42s6500 Led Full Hd 42  220v      Tcl    9.0  12.0  \n",
       "2         Tv Samsung Smart Tv Hd 32 Para Repuestos  Samsung    3.0  10.0  \n",
       "3            Tv Led Samsung 46 Smart Pantalla Rota  Samsung    7.0  14.0  \n",
       "4                                Tv 29 Sanyo Vizon    Sanyo    6.0  11.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./training_data/tv_ner_textcat_1077.csv')\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ff1101e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1077\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DATA = []\n",
    "\n",
    "for index, row in data.iterrows(): \n",
    "    text = row['Title']\n",
    "    start = row['start']\n",
    "    end = row['end']\n",
    "    entities = []\n",
    "    #print(start)\n",
    "    if math.isnan(start):\n",
    "        pass\n",
    "        #print('no ent')\n",
    "    else:        \n",
    "        entities.append((int(start), int(end), \"MARCA\"))            \n",
    "        \n",
    "    \n",
    "    #print(dup_start)\n",
    "    training_example = (text, {\"entities\": entities})\n",
    "    TRAINING_DATA.append(training_example)\n",
    "\n",
    "print(len(TRAINING_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b2a15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "861\n",
      "216\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "#TRAINING_DATA\n",
    "random.seed(0)\n",
    "l = list(TRAINING_DATA)\n",
    "random.shuffle(l)\n",
    "#print(l)\n",
    "length = len(TRAINING_DATA)\n",
    "index_80 = length*0.80\n",
    "train = l[:int(index_80)]\n",
    "dev = l[int(index_80):]\n",
    "print(len(train))\n",
    "print(len(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a86daad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import srsly\n",
    "from spacy.gold import docs_to_json, biluo_tags_from_offsets, spans_from_biluo_tags\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "nlp = spacy.load('es_core_news_sm', disable = ['tagger', 'ner'])\n",
    "#nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "nlp.max_length = 1500000\n",
    "\n",
    "def spacy_format(data, test_train):    \n",
    "    docs = []\n",
    "    for text, annot in tqdm(data):\n",
    "        if len(text) < 1000000:\n",
    "            doc = nlp(text)\n",
    "            tags = biluo_tags_from_offsets(doc, annot['entities'])\n",
    "            entities = spans_from_biluo_tags(doc, tags)\n",
    "            doc.ents = entities\n",
    "            docs.append(doc)\n",
    "\n",
    "    srsly.write_json(f'./training_data/cel_ner_1077_{test_train}.json', [docs_to_json(docs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6feb29ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 535/861 [00:00<00:00, 779.54it/s]/tmp/ipykernel_14796/3468165033.py:16: UserWarning: [W030] Some entities could not be aligned in the text \"Tv 14 Hitachi/ Broksonic/ Admiral/ Top House/ Vari...\" with entities \"[(15, 24, 'MARCA')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  tags = biluo_tags_from_offsets(doc, annot['entities'])\n",
      "100%|██████████| 861/861 [00:01<00:00, 772.15it/s]\n",
      "100%|██████████| 216/216 [00:00<00:00, 793.02it/s]\n"
     ]
    }
   ],
   "source": [
    "spacy_format(train, 'train')\n",
    "spacy_format(dev, 'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0124e775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "=========================== Data format validation ===========================\u001b[0m\n",
      "\u001b[2K\u001b[38;5;2m✔ Corpus is loadable\u001b[0m\n",
      "\u001b[1m\n",
      "=============================== Training stats ===============================\u001b[0m\n",
      "Training pipeline: tagger, parser, ner\n",
      "Starting with blank model 'es'\n",
      "861 training docs\n",
      "216 evaluation docs\n",
      "\u001b[38;5;3m⚠ 9 training examples also in evaluation data\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples to train from a blank model (861)\u001b[0m\n",
      "It's recommended to use at least 2000 examples (minimum 100)\n",
      "\u001b[1m\n",
      "============================== Vocab & Vectors ==============================\u001b[0m\n",
      "\u001b[38;5;4mℹ 6622 total words in the data (957 unique)\u001b[0m\n",
      "10 most common words: 'Tv' (625), 'Smart' (339), ' ' (275), 'Led' (274),\n",
      "'Pulgadas' (204), 'Televisor' (200), '32' (186), 'Samsung' (155), 'Hd' (154),\n",
      "'4k' (123)\n",
      "\u001b[38;5;4mℹ No word vectors present in the model\u001b[0m\n",
      "\u001b[1m\n",
      "========================== Named Entity Recognition ==========================\u001b[0m\n",
      "\u001b[38;5;4mℹ 1 new label, 0 existing labels\u001b[0m\n",
      "0 missing values (tokens with '-' label)\n",
      "New: 'MARCA' (779)\n",
      "\u001b[38;5;2m✔ Good amount of examples for all labels\u001b[0m\n",
      "\u001b[38;5;2m✔ Examples without occurrences available for all labels\u001b[0m\n",
      "\u001b[38;5;2m✔ No entities consisting of or starting/ending with whitespace\u001b[0m\n",
      "\u001b[38;5;2m✔ No entities consisting of or starting/ending with punctuation\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Part-of-speech Tagging ===========================\u001b[0m\n",
      "\u001b[38;5;4mℹ 1 label in data (303 labels in tag map)\u001b[0m\n",
      "'-' (6622)\n",
      "\u001b[38;5;1m✘ Label '-' not found in tag map for language 'es'\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Dependency Parsing =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Found 925 sentences with an average length of 7.2 words.\u001b[0m\n",
      "\u001b[38;5;4mℹ 28 labels in train data\u001b[0m\n",
      "\u001b[38;5;4mℹ 28 labels in projectivized train data\u001b[0m\n",
      "'flat' (3124), 'ROOT' (925), 'nummod' (894), '' (304), 'punct' (285), 'case'\n",
      "(232), 'appos' (196), 'dep' (114), 'obj' (104), 'nsubj' (99), 'nmod' (99),\n",
      "'conj' (72), 'cc' (65), 'advmod' (24), 'mark' (19), 'amod' (19), 'obl' (15),\n",
      "'det' (13), 'compound' (6), 'acl' (4), 'advcl' (2), 'aux' (1), 'ccomp' (1),\n",
      "'cop' (1), 'expl:pass' (1), 'parataxis' (1), 'csubj' (1), 'xcomp' (1)\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'mark' (19)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'obl' (15)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'amod' (19)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'advcl' (2)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'aux' (1)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'ccomp' (1)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'acl' (4)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'det' (13)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'compound' (6)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'cop' (1)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'expl:pass' (1)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'parataxis' (1)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'csubj' (1)\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'xcomp' (1)\u001b[0m\n",
      "\u001b[38;5;3m⚠ The following labels were found only in the train data: expl:pass,\n",
      "acl, xcomp, parataxis, ccomp, aux, compound\u001b[0m\n",
      "To train a parser, your data should include at least 20 instances of each label.\n",
      "\u001b[1m\n",
      "================================== Summary ==================================\u001b[0m\n",
      "\u001b[38;5;2m✔ 5 checks passed\u001b[0m\n",
      "\u001b[38;5;3m⚠ 17 warnings\u001b[0m\n",
      "\u001b[38;5;1m✘ 1 error\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Debug\n",
    "!python3 -m spacy debug-data es '/home/fede/kaggle/desafio_ia_nlp_nubimetrics/spacy_ner/TVs/training_data/cel_ner_1077_train.json' '/home/fede/kaggle/desafio_ia_nlp_nubimetrics/spacy_ner/TVs/training_data/cel_ner_1077_dev.json' --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f93278ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created output directory: models/NUBI-TV-NER-1077\u001b[0m\n",
      "Training pipeline: ['ner']\n",
      "Starting with base model 'es_core_news_sm'\n",
      "Replacing component from base model 'ner'\n",
      "Counting training words (limit=0)\n",
      "/home/fede/anaconda3/envs/spacy_env/lib/python3.8/site-packages/spacy/language.py:635: UserWarning: [W033] Training a new parser or NER using a model with an empty lexeme normalization table. This may degrade the performance to some degree. If this is intentional or this language doesn't have a normalization table, please ignore this warning.\n",
      "  proc.begin_training(\n",
      "\n",
      "Itn  NER Loss   NER P   NER R   NER F   Token %  CPU WPS\n",
      "---  ---------  ------  ------  ------  -------  -------\n",
      "  1   1011.988  91.753  94.180  92.950  100.000    32877                        \n",
      "  2     94.645  96.335  97.354  96.842  100.000    33175                        \n",
      "  3     53.151  95.855  97.884  96.859  100.000    30219                        \n",
      "  4     22.009  96.335  97.354  96.842  100.000    32944                        \n",
      "  5     20.810  95.361  97.884  96.606  100.000    34055                        \n",
      "  6     18.319  97.354  97.354  97.354  100.000    34182                        \n",
      "  7     17.094  95.833  97.354  96.588  100.000    33989                        \n",
      "  8     20.876  95.312  96.825  96.063  100.000    34650                        \n",
      "  9      6.574  95.812  96.825  96.316  100.000    34357                        \n",
      " 10     15.297  95.812  96.825  96.316  100.000    34191                        \n",
      " 11     14.268  94.792  96.296  95.538  100.000    34055                        \n",
      " 12     10.522  94.792  96.296  95.538  100.000    33719                        \n",
      " 13     14.078  95.812  96.825  96.316  100.000    34351                        \n",
      " 14      6.898  96.825  96.825  96.825  100.000    33045                        \n",
      " 15      4.740  96.825  96.825  96.825  100.000    34258                        \n",
      " 16      1.391  96.316  96.825  96.570  100.000    34227                        \n",
      " 17      4.481  96.316  96.825  96.570  100.000    33367                        \n",
      " 18      1.201  95.812  96.825  96.316  100.000    33150                        \n",
      " 19      2.053  95.789  96.296  96.042  100.000    34537                        \n",
      " 20      2.000  96.296  96.296  96.296  100.000    34483                        \n",
      " 21      0.437  95.288  96.296  95.789  100.000    34187                        \n",
      " 22      2.331  95.288  96.296  95.789  100.000    33996                        \n",
      " 23      1.843  95.288  96.296  95.789  100.000    34199                        \n",
      " 24      0.002  94.792  96.296  95.538  100.000    34440                        \n",
      " 25      0.279  94.792  96.296  95.538  100.000    34174                        \n",
      " 26      1.736  94.271  95.767  95.013  100.000    33808                        \n",
      " 27      0.024  94.271  95.767  95.013  100.000    34585                        \n",
      " 28      1.032  94.271  95.767  95.013  100.000    34392                        \n",
      " 29      0.321  94.271  95.767  95.013  100.000    34238                        \n",
      " 30      2.339  94.301  96.296  95.288  100.000    33847                        \n",
      "\u001b[38;5;2m✔ Saved model to output directory\u001b[0m\n",
      "models/NUBI-TV-NER-1077/model-final\n",
      "\u001b[2K\u001b[38;5;2m✔ Created best model\u001b[0m\n",
      "models/NUBI-TV-NER-1077/model-best\n"
     ]
    }
   ],
   "source": [
    "# Train 1077 data\n",
    "!python -m spacy train es ./models/NUBI-TV-NER-1077 '/home/fede/kaggle/desafio_ia_nlp_nubimetrics/spacy_ner/TVs/training_data/cel_ner_1077_train.json' '/home/fede/kaggle/desafio_ia_nlp_nubimetrics/spacy_ner/TVs/training_data/cel_ner_1077_dev.json' --base-model 'es_core_news_sm' -p ner -R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f62174b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Encrypted_Seller</th>\n",
       "      <th>Encrypted_Id</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b10532ee783f9545d7bddd8f9da20d2a8d1642a486caf5...</td>\n",
       "      <td>63c875becd6c78649539497bdd134c2c762f610b3616ae...</td>\n",
       "      <td>Smart Tv Noblex Di43x5100x Led Full Hd 43  220v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>aa4dd7ba40c80cf15a859c19f2500e328797e2251322d4...</td>\n",
       "      <td>490e4b75cfa66087c95b20fb6546e4dfdc952f7537a8e3...</td>\n",
       "      <td>Smart Tv Tcl L42s6500 Led Full Hd 42  220v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>e48526711c7cd386af46750540bf107acac9b5988b515a...</td>\n",
       "      <td>eab7301d49cd3bbe3bcd3c196da0d61713de45b44523c1...</td>\n",
       "      <td>Tv Samsung Smart Tv Hd 32 Para Repuestos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9e527f7876123f50719291aed05c8351bab1ae9abacadb...</td>\n",
       "      <td>daf900de69964f2cf241ed5395ac74edd1f2deb6577356...</td>\n",
       "      <td>Tv Led Samsung 46 Smart Pantalla Rota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cf3021aa458178431fa2f22daa52ee17f005d6728d9b35...</td>\n",
       "      <td>b244c68806fab7d7d523a3927a4eb6381610c40313e8bb...</td>\n",
       "      <td>Tv 29 Sanyo Vizon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                   Encrypted_Seller  \\\n",
       "0           0  b10532ee783f9545d7bddd8f9da20d2a8d1642a486caf5...   \n",
       "1           1  aa4dd7ba40c80cf15a859c19f2500e328797e2251322d4...   \n",
       "2           2  e48526711c7cd386af46750540bf107acac9b5988b515a...   \n",
       "3           3  9e527f7876123f50719291aed05c8351bab1ae9abacadb...   \n",
       "4           4  cf3021aa458178431fa2f22daa52ee17f005d6728d9b35...   \n",
       "\n",
       "                                        Encrypted_Id  \\\n",
       "0  63c875becd6c78649539497bdd134c2c762f610b3616ae...   \n",
       "1  490e4b75cfa66087c95b20fb6546e4dfdc952f7537a8e3...   \n",
       "2  eab7301d49cd3bbe3bcd3c196da0d61713de45b44523c1...   \n",
       "3  daf900de69964f2cf241ed5395ac74edd1f2deb6577356...   \n",
       "4  b244c68806fab7d7d523a3927a4eb6381610c40313e8bb...   \n",
       "\n",
       "                                             Title  \n",
       "0  Smart Tv Noblex Di43x5100x Led Full Hd 43  220v  \n",
       "1       Smart Tv Tcl L42s6500 Led Full Hd 42  220v  \n",
       "2         Tv Samsung Smart Tv Hd 32 Para Repuestos  \n",
       "3            Tv Led Samsung 46 Smart Pantalla Rota  \n",
       "4                                Tv 29 Sanyo Vizon  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inference 1077\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('./models/NUBI-TV-NER-1077/model-best')\n",
    "evaluate = pd.read_csv('../../TVs.csv')\n",
    "evaluate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60a99cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "marca = []\n",
    "start = []\n",
    "end = []\n",
    "\n",
    "for doc in nlp.pipe(evaluate['Title']):    \n",
    "    #displacy.render(doc, style=\"ent\")\n",
    "    ent_count = 0\n",
    "    for ent in doc.ents:\n",
    "        #print(doc.text, ent.text, ent.start_char, ent.end_char)\n",
    "        if ent_count == 1:\n",
    "            pass\n",
    "        else:        \n",
    "            marca.append(ent.text)\n",
    "            start.append(ent.start_char)\n",
    "            end.append(ent.end_char)\n",
    "            ent_count = 1\n",
    "    if ent_count == 0:    \n",
    "        marca.append('##REV')\n",
    "        start.append('##REV')\n",
    "        end.append('##REV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fd0a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = evaluate.loc[:, :].copy()\n",
    "df_all['marca'] = marca\n",
    "df_all['start'] = start\n",
    "df_all['end'] = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db3169e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(\"./final_bd_tv_ner_all.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
